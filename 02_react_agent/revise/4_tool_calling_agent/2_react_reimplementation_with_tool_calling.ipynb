{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76e18d7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeyaprakashrajagopal/vscode_projects/Langchain-Projects/.venv/lib/python3.13/site-packages/langchain_tavily/tavily_research.py:97: UserWarning: Field name \"output_schema\" in \"TavilyResearch\" shadows an attribute in parent \"BaseTool\"\n",
      "  class TavilyResearch(BaseTool):  # type: ignore[override, override]\n",
      "/Users/jeyaprakashrajagopal/vscode_projects/Langchain-Projects/.venv/lib/python3.13/site-packages/langchain_tavily/tavily_research.py:97: UserWarning: Field name \"stream\" in \"TavilyResearch\" shadows an attribute in parent \"BaseTool\"\n",
      "  class TavilyResearch(BaseTool):  # type: ignore[override, override]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, ToolMessage, AIMessage\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain.tools import BaseTool\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.callbacks import BaseCallbackHandler\n",
    "from langchain_tavily import TavilySearch\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d8b7ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "from uuid import UUID\n",
    "from langchain_core.outputs import LLMResult\n",
    "\n",
    "class AgentCallbackHandler(BaseCallbackHandler):\n",
    "    def on_llm_start(\n",
    "            self,\n",
    "            serialized: dict[str, Any],\n",
    "            prompts: list[str],\n",
    "            *,\n",
    "            run_id: UUID,\n",
    "            parent_run_id: UUID | None = None,\n",
    "            tags: list[str] | None = None,\n",
    "            metadata: dict[str, Any] | None = None,\n",
    "            **kwargs: Any,\n",
    "        ) -> Any:\n",
    "            \"\"\"Run when LLM starts running.\n",
    "\n",
    "            !!! warning\n",
    "                This method is called for non-chat models (regular LLMs). If you're\n",
    "                implementing a handler for a chat model, you should use\n",
    "                `on_chat_model_start` instead.\n",
    "\n",
    "            Args:\n",
    "                serialized: The serialized LLM.\n",
    "                prompts: The prompts.\n",
    "                run_id: The run ID. This is the ID of the current run.\n",
    "                parent_run_id: The parent run ID. This is the ID of the parent run.\n",
    "                tags: The tags.\n",
    "                metadata: The metadata.\n",
    "                **kwargs: Additional keyword arguments.\n",
    "            \"\"\"\n",
    "            print(f\"Prompt to llm was: ***\\n{prompts[0]}\")\n",
    "            print(\"******\")\n",
    "    \n",
    "    def on_llm_end(\n",
    "        self,\n",
    "        response: LLMResult,\n",
    "        *,\n",
    "        run_id: UUID,\n",
    "        parent_run_id: UUID | None = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> Any:\n",
    "        \"\"\"Run when LLM ends running.\n",
    "\n",
    "        Args:\n",
    "            response: The response which was generated.\n",
    "            run_id: The run ID. This is the ID of the current run.\n",
    "            parent_run_id: The parent run ID. This is the ID of the parent run.\n",
    "            **kwargs: Additional keyword arguments.\n",
    "        \"\"\"\n",
    "        print(f\"***LLM Response***:***\\n{response.generations[0][0].text}\")\n",
    "        print(\"******\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36d18f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "def find_tool_by_name(tools: List[BaseTool], tool_name) -> BaseTool:\n",
    "    for tool_1 in tools:\n",
    "        if tool_name == tool_1.name:\n",
    "            return tool_1\n",
    "    return ValueError(f\"Tool with the name {tool_name}couldn't be found \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8590b430",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt to llm was: ***\n",
      "Human: What is the weather in frankfurt?\n",
      "******\n",
      "***LLM Response***:***\n",
      "\n",
      "******\n",
      "Prompt to llm was: ***\n",
      "Human: What is the weather in frankfurt?\n",
      "AI: [{'name': 'tavily_search', 'args': {'include_images': False, 'query': 'current weather in Frankfurt', 'search_depth': 'basic'}, 'id': '398763c8-a3b3-4e49-b0e4-74f15c4a6b53', 'type': 'tool_call'}]\n",
      "Tool: {'query': 'current weather in Frankfurt', 'follow_up_questions': None, 'answer': None, 'images': [], 'results': [{'title': 'Weather in Frankfurt', 'url': 'https://www.weatherapi.com/', 'content': \"{'location': {'name': 'Frankfurt', 'region': 'Hessen', 'country': 'Germany', 'lat': 50.1167, 'lon': 8.6833, 'tz_id': 'Europe/Berlin', 'localtime_epoch': 1767349716, 'localtime': '2026-01-02 11:28'}, 'current': {'last_updated_epoch': 1767348900, 'last_updated': '2026-01-02 11:15', 'temp_c': 3.3, 'temp_f': 37.9, 'is_day': 1, 'condition': {'text': 'Patchy heavy snow', 'icon': '//cdn.weatherapi.com/weather/64x64/day/335.png', 'code': 1222}, 'wind_mph': 12.5, 'wind_kph': 20.2, 'wind_degree': 254, 'wind_dir': 'WSW', 'pressure_mb': 1001.0, 'pressure_in': 29.56, 'precip_mm': 0.42, 'precip_in': 0.02, 'humidity': 65, 'cloud': 0, 'feelslike_c': -1.1, 'feelslike_f': 30.0, 'windchill_c': -3.4, 'windchill_f': 25.9, 'heatindex_c': 1.5, 'heatindex_f': 34.6, 'dewpoint_c': -3.2, 'dewpoint_f': 26.2, 'vis_km': 10.0, 'vis_miles': 6.0, 'uv': 0.4, 'gust_mph': 15.5, 'gust_kph': 25.0}}\", 'score': 0.9939101, 'raw_content': None}, {'url': 'https://www.weather25.com/europe/germany/hesse/frankfurt?page=month&month=February', 'title': 'Frankfurt weather in February 2026 | Weather25.com', 'content': 'The weather in Frankfurt in February is very cold with temperatures between 32°F and 42°F, warm clothes are a must. You can expect about 3 to 8 days of rain', 'score': 0.91288006, 'raw_content': None}, {'url': 'https://en.climate-data.org/europe/germany/hesse/frankfurt-am-main-447/t/february-2/', 'title': 'Weather Frankfurt am Main in February 2026 - Climate Data', 'content': 'February in Frankfurt typically experiences chilly weather. The average temperature during this month is around 36.5°F (2.5°C).', 'score': 0.9008183, 'raw_content': None}, {'url': 'https://www.weather2travel.com/germany/frankfurt/february/', 'title': 'Frankfurt weather in February 2026 | Germany: How hot?', 'content': 'Frankfurt weather in February 2026. Expect daytime maximum temperatures of 5°C in Frankfurt, Germany in February based on long-term weather averages.', 'score': 0.8703443, 'raw_content': None}, {'url': 'https://www.easeweather.com/europe/germany/bavaria/regierungsbezirk-mittelfranken/frankfurt/january', 'title': 'Weather in Frankfurt in January 2026 - Detailed Forecast', 'content': 'According to Frankfurt snow forecast for January 2026, 11 snowy days are expected in the next 2 weeks. The closest date with snow is Friday, 2 January.', 'score': 0.8506799, 'raw_content': None}], 'response_time': 2.32, 'request_id': 'eaf47059-e034-4281-a304-8f5d855d5a9d'}\n",
      "******\n",
      "***LLM Response***:***\n",
      "**Frankfurt (Germany) – Current Weather (as of 2026‑01‑02 11:28 CET)**  \n",
      "- **Temperature:** 3.3 °C (37.9 °F)  \n",
      "- **Condition:** Patchy heavy snow  \n",
      "- **Wind:** 20 km/h (12.5 mph) from the WSW  \n",
      "- **Humidity:** 65 %  \n",
      "- **Feels‑like:** –1.1 °C (30 °F)  \n",
      "- **Precipitation:** 0.42 mm (0.02 in) today  \n",
      "- **Visibility:** 10 km (6 mi)  \n",
      "\n",
      "*Source: WeatherAPI.com (current forecast for Frankfurt)*\n",
      "******\n",
      "**Frankfurt (Germany) – Current Weather (as of 2026‑01‑02 11:28 CET)**  \n",
      "- **Temperature:** 3.3 °C (37.9 °F)  \n",
      "- **Condition:** Patchy heavy snow  \n",
      "- **Wind:** 20 km/h (12.5 mph) from the WSW  \n",
      "- **Humidity:** 65 %  \n",
      "- **Feels‑like:** –1.1 °C (30 °F)  \n",
      "- **Precipitation:** 0.42 mm (0.02 in) today  \n",
      "- **Visibility:** 10 km (6 mi)  \n",
      "\n",
      "*Source: WeatherAPI.com (current forecast for Frankfurt)*\n"
     ]
    }
   ],
   "source": [
    "tools = [TavilySearch()]\n",
    "llm = ChatOllama(model=\"gpt-oss:20b\", temperature=0, callbacks=[AgentCallbackHandler()])\n",
    "llm_with_tools = llm.bind_tools(tools=tools)\n",
    "\n",
    "messages = [\n",
    "    HumanMessage(content=\"What is the weather in frankfurt?\")\n",
    "]\n",
    "\n",
    "while True:\n",
    "    ai_message = llm_with_tools.invoke(messages)\n",
    "    messages.append(ai_message)\n",
    "\n",
    "    tool_calls = getattr(ai_message, \"tool_calls\", None) or []\n",
    "    \n",
    "    if len(tool_calls) > 0:\n",
    "        for tool_call in tool_calls:\n",
    "            tool_name = tool_call.get(\"name\")\n",
    "            tool_args = tool_call.get(\"args\", {})\n",
    "            tool_call_id = tool_call.get(\"id\")\n",
    "\n",
    "            tool_to_use = find_tool_by_name(tools, tool_name)\n",
    "            observation = tool_to_use.invoke(tool_args)\n",
    "            messages.append(ToolMessage(\n",
    "                content=str(observation),\n",
    "                tool_call_id=tool_call_id\n",
    "            ))\n",
    "        continue\n",
    "    \n",
    "    print(ai_message.content)\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ee59aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-projects",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
